import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import time
import os
import hashlib
import json
from tempfile import NamedTemporaryFile

# é…ç½®å‚æ•°
MODEL_PATH = "best.pt"
ALARM_SOUND = "alarm.mp3"
MAX_HISTORY = 5
CONF_THRESHOLD = 0.5
ALARM_DURATION = 1
USER_DATA_FILE = "users.json"

# åˆå§‹åŒ–ç”¨æˆ·æ•°æ®
def initialize_users():
    if not os.path.exists(USER_DATA_FILE):
        with open(USER_DATA_FILE, "w") as f:
            json.dump({}, f)


def register_user(username, password):
    with open(USER_DATA_FILE, "r") as f:
        users = json.load(f)
    if username in users:
        return False
    salt = os.urandom(32)
    key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)
    users[username] = {
        'salt': salt.hex(),
        'key': key.hex()
    }
    with open(USER_DATA_FILE, "w") as f:
        json.dump(users, f)
    return True


def verify_user(username, password):
    with open(USER_DATA_FILE, "r") as f:
        users = json.load(f)
    if username not in users:
        return False
    user = users[username]
    salt = bytes.fromhex(user['salt'])
    key = bytes.fromhex(user['key'])
    new_key = hashlib.pbkdf2_hmac('sha256', password.encode('utf-8'), salt, 100000)
    return key == new_key


# åˆå§‹åŒ–ç”¨æˆ·æ•°æ®
initialize_users()


# è‡ªå®šä¹‰æ ·å¼
def set_custom_style():
    st.markdown(f"""
        <style>
            .main {{ background: #f8f9fa; }}
            .stAlert {{ border-radius: 15px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }}
            .video-container {{
                position: relative;
                padding: 20px;
                background: white;
                border-radius: 15px;
                margin: 15px 0;
                box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            }}
            .status-badge {{
                position: absolute;
                top: 25px;
                right: 25px;
                z-index: 100;
                padding: 8px 15px;
                border-radius: 20px;
                font-weight: bold;
            }}
            #alarm-audio {{ display: none; }}
            .auth-container {{ 
                max-width: 400px;
                margin: 2rem auto;
                padding: 2rem;
                background: white;
                border-radius: 15px;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            }}
        </style>
    """, unsafe_allow_html=True)


@st.cache_resource
def load_model():
    try:
        return YOLO(MODEL_PATH)
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        st.stop()


def auth_component():
    set_custom_style()
    with st.container():
        st.markdown("<div class='auth-container'>", unsafe_allow_html=True)
        st.title("ç”¨æˆ·è®¤è¯ ğŸ”")

        if 'auth_view' not in st.session_state:
            st.session_state.auth_view = "ç™»å½•"

        auth_mode = st.radio(
            "è¯·é€‰æ‹©æ“ä½œ",
            ["ç™»å½•", "æ³¨å†Œ"],
            key="auth_radio",
            index=0 if st.session_state.auth_view == "ç™»å½•" else 1
        )

        username = st.text_input("ç”¨æˆ·å", key="auth_username")
        password = st.text_input("å¯†ç ", type="password", key="auth_password")

        if auth_mode == "æ³¨å†Œ":
            confirm_password = st.text_input("ç¡®è®¤å¯†ç ", type="password")
            if st.button("æ³¨å†Œ"):
                if password != confirm_password:
                    st.error("å¯†ç ä¸ä¸€è‡´")
                elif len(password) < 6:
                    st.error("å¯†ç è‡³å°‘éœ€è¦6ä½")
                elif not username:
                    st.error("ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
                else:
                    if register_user(username, password):
                        st.success("æ³¨å†ŒæˆåŠŸï¼Œè¯·ç™»å½•")
                        st.session_state.auth_view = "ç™»å½•"
                        st.rerun()
                    else:
                        st.error("ç”¨æˆ·åå·²å­˜åœ¨")
        else:
            if st.button("ç™»å½•"):
                if verify_user(username, password):
                    st.session_state.authenticated = True
                    st.session_state.username = username
                    st.rerun()
                else:
                    st.error("ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        st.markdown("</div>", unsafe_allow_html=True)


def handle_audio_permission():
    """è‡ªåŠ¨å¤„ç†éŸ³é¢‘æ’­æ”¾æƒé™"""
    autoplay_script = """
    <script>
    (function() {
        const audioElement = document.getElementById('alarm-audio');

        // è‡ªåŠ¨é™éŸ³åˆå§‹åŒ–
        const initAudio = () => {
            audioElement.muted = true;
            audioElement.play()
                .then(() => {
                    audioElement.pause();
                    audioElement.muted = false;
                    window.audioInitialized = true;
                })
                .catch(error => console.log('è‡ªåŠ¨åˆå§‹åŒ–å®Œæˆ'));
        }

        // é¦–æ¬¡åŠ è½½åˆå§‹åŒ–
        if(document.readyState === 'complete') {
            initAudio();
        } else {
            document.addEventListener('DOMContentLoaded', initAudio);
        }

        // å¤„ç†é¡µé¢å˜åŒ–æ—¶çš„é‡æ–°åˆå§‹åŒ–
        document.addEventListener('visibilitychange', () => {
            if (!document.hidden) initAudio();
        });
    })();
    </script>
    """
    st.components.v1.html(autoplay_script)


def play_alarm():
    """è§¦å‘è­¦æŠ¥å£°éŸ³"""
    play_script = """
    <script>
    (function() {
        const audio = document.getElementById('alarm-audio');
        if(window.audioInitialized) {
            audio.play().catch(error => {
                console.log('è‡ªåŠ¨æ’­æ”¾å¤±è´¥ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–');
                audio.muted = true;
                audio.play().then(() => {
                    audio.pause();
                    audio.muted = false;
                    audio.play();
                });
            });
        }
    })();
    </script>
    """
    st.components.v1.html(play_script, height=0)


def handle_image_detection(model):
    st.subheader("å›¾ç‰‡æ£€æµ‹")
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"], key="image_uploader")

    if uploaded_file:
        if not os.path.exists(ALARM_SOUND):
            st.error(f"è­¦æŠ¥éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {ALARM_SOUND}")
            return

        start_time = time.time()
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

        with st.spinner("æ­£åœ¨åˆ†æ..."):
            results = model.predict(img, conf=CONF_THRESHOLD)
            annotated_img = results[0].plot()

            detected_classes = []
            for box in results[0].boxes:
                if box.conf > CONF_THRESHOLD:
                    detected_classes.append(model.names[int(box.cls)])

            fire_detected = any(cls in ['Fire', 'smoke'] for cls in detected_classes)
            process_time = time.time() - start_time

            record = {
                "time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "has_Fire": fire_detected,
                "result": "å‘ç°å±é™©" if fire_detected else "ç¯å¢ƒå®‰å…¨",
                "process_time": process_time,
                "type": "image"
            }
            st.session_state.history.append(record)

            col1, col2 = st.columns(2)
            with col1:
                st.image(img, channels="BGR", caption="åŸå§‹å›¾ç‰‡")
            with col2:
                st.image(annotated_img, channels="BGR", caption="æ£€æµ‹ç»“æœ")

            if fire_detected:
                st.error("## ğŸš¨ æ£€æµ‹åˆ°ç«ç¾å±é™©ï¼")
                play_alarm()
            else:
                st.success("## âœ… ç¯å¢ƒå®‰å…¨")


def handle_video_detection(model):
    st.subheader("è§†é¢‘æ£€æµ‹")
    uploaded_file = st.file_uploader("ä¸Šä¼ è§†é¢‘", type=["mp4", "avi", "mov"], key="video_uploader")

    if uploaded_file and not st.session_state.video_processing:
        if not os.path.exists(ALARM_SOUND):
            st.error(f"è­¦æŠ¥éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {ALARM_SOUND}")
            return

        st.session_state.video_processing = True
        video_path = f"temp_{uploaded_file.name}"

        with open(video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        required_frames = max(1, int(fps * ALARM_DURATION))

        frame_placeholder = st.empty()
        progress_bar = st.progress(0)
        alarm_zone = st.empty()
        consecutive_danger_frames = 0
        alarm_triggered = False
        alarm_flag = False
        processed_frames = 0
        start_time = time.time()

        while st.session_state.video_processing and cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            results = model.predict(frame, conf=CONF_THRESHOLD)
            annotated_frame = results[0].plot()

            detected_classes = []
            for box in results[0].boxes:
                if box.conf > CONF_THRESHOLD:
                    detected_classes.append(model.names[int(box.cls)])

            fire_detected = any(cls in ['Fire', 'smoke'] for cls in detected_classes)

            if fire_detected:
                consecutive_danger_frames += 1
                duration = consecutive_danger_frames / fps

                if consecutive_danger_frames >= required_frames:
                    if not alarm_triggered:
                        play_alarm()
                        alarm_triggered = True
                        alarm_flag = True
                    alarm_zone.error(f"## ğŸš¨ æŒç»­å±é™©ï¼å·²æŒç»­ {duration:.1f} ç§’")
                else:
                    alarm_zone.warning(f"## âš ï¸ æ£€æµ‹åˆ°å±é™©ï¼å·²æŒç»­ {duration:.1f} ç§’")
            else:
                consecutive_danger_frames = 0
                alarm_triggered = False
                alarm_zone.empty()

            frame_placeholder.image(annotated_frame, channels="BGR", use_column_width=True)
            progress_bar.progress((processed_frames + 1) / total_frames)
            processed_frames += 1

        process_time = time.time() - start_time
        cap.release()
        st.session_state.video_processing = False

        if alarm_flag:
            st.error(f"## ğŸš¨ æ£€æµ‹åˆ°æŒç»­{ALARM_DURATION}ç§’çš„ç«ç¾å±é™©ï¼")
        else:
            st.success("## âœ… è§†é¢‘åˆ†æå®Œæˆï¼Œæœªå‘ç°æŒç»­å±é™©")

        record = {
            "time": time.strftime("%Y-%m-%d %H:%M:%S"),
            "has_Fire": alarm_flag,
            "result": "å‘ç°å±é™©" if alarm_flag else "ç¯å¢ƒå®‰å…¨",
            "process_time": process_time,
            "frames": processed_frames,
            "type": "video"
        }
        st.session_state.history.append(record)


def handle_realtime_detection(model):
    st.subheader("å®æ—¶æ£€æµ‹")

    # äº‘ç«¯ç¯å¢ƒæç¤º
    if os.environ.get('IS_STREAMLIT_CLOUD', False):
        st.info("""
        ğŸ’¡ äº‘ç«¯æ£€æµ‹æç¤ºï¼š
        1. ä½¿ç”¨ä¸‹æ–¹ä¸Šä¼ è§†é¢‘æ¨¡æ‹Ÿå®æ—¶æ£€æµ‹
        2. æœ¬åœ°è¿è¡Œæ—¶ä»å¯ä½¿ç”¨æ‘„åƒå¤´
        """)

        # å¤‡ç”¨è§†é¢‘ä¸Šä¼ æ–¹æ¡ˆ
        uploaded_file = st.file_uploader("ä¸Šä¼ æµ‹è¯•è§†é¢‘", type=["mp4"])
        if uploaded_file:
            # å¤ç”¨è§†é¢‘æ£€æµ‹é€»è¾‘
            handle_video_detection(model)
        return

    # æœ¬åœ°æ‘„åƒå¤´æ£€æµ‹
    run_camera = st.checkbox("å¼€å¯æ‘„åƒå¤´")
    frame_placeholder = st.empty()
    alarm_zone = st.empty()
    status_bar = st.empty()

    danger_start_time = None
    alarm_triggered = False
    consecutive_danger_frames = 0

    if run_camera:
        try:
            cap = cv2.VideoCapture(0)
            if not cap.isOpened():
                raise RuntimeError("æ— æ³•è®¿é—®æ‘„åƒå¤´è®¾å¤‡")

            fps = cap.get(cv2.CAP_PROP_FPS) or 30
            required_frames = max(1, int(fps * ALARM_DURATION))

            while run_camera:
                ret, frame = cap.read()
                if not ret:
                    status_bar.error("æ— æ³•è·å–æ‘„åƒå¤´ç”»é¢")
                    break

                # æ¨ç†æ£€æµ‹
                results = model.predict(frame, conf=CONF_THRESHOLD)
                annotated_frame = results[0].plot()

                # åˆ†æç»“æœ
                detected_classes = [
                    model.names[int(box.cls)]
                    for box in results[0].boxes
                    if box.conf > CONF_THRESHOLD
                ]
                fire_detected = any(cls in ['Fire', 'smoke'] for cls in detected_classes)

                # è­¦æŠ¥é€»è¾‘
                if fire_detected:
                    consecutive_danger_frames += 1
                    duration = consecutive_danger_frames / fps

                    if consecutive_danger_frames >= required_frames:
                        if not alarm_triggered:
                            play_alarm()
                            alarm_triggered = True
                        alarm_zone.error(f"## ğŸš¨ æŒç»­å±é™©ï¼å·²æŒç»­ {duration:.1f} ç§’")
                    else:
                        alarm_zone.warning(f"## âš ï¸ æ£€æµ‹åˆ°å±é™©ï¼å·²æŒç»­ {duration:.1f} ç§’")
                else:
                    consecutive_danger_frames = 0
                    alarm_triggered = False
                    alarm_zone.empty()

                # æ˜¾ç¤ºç”»é¢
                frame_placeholder.image(annotated_frame, channels="BGR", use_column_width=True)

        except Exception as e:
            st.error(f"æ‘„åƒå¤´è®¿é—®å¤±è´¥ï¼š{str(e)}")
        finally:
            if 'cap' in locals():
                cap.release()
            cv2.destroyAllWindows()


def main_app():
    st.set_page_config(
        page_title="åŸºäºYOLOçš„ç«ç¾æ£€æµ‹ç³»ç»Ÿè®¾è®¡ä¸å®ç°",
        page_icon="ğŸ”¥",
        layout="wide"
    )
    set_custom_style()
    model = load_model()

    # åˆå§‹åŒ–sessionçŠ¶æ€
    session_defaults = {
        "history": [],
        "video_processing": False
    }
    for key, value in session_defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

    # éŸ³é¢‘å…ƒç´ å’Œæƒé™å¤„ç†
    st.markdown(f'''
        <audio id="alarm-audio" controls style="display:none;">
            <source src="{ALARM_SOUND}" type="audio/mpeg">
        </audio>
    ''', unsafe_allow_html=True)
    handle_audio_permission()

    st.title("ğŸ”¥ åŸºäºYOLOçš„ç«ç¾æ£€æµ‹ç³»ç»Ÿè®¾è®¡ä¸å®ç°")
    st.markdown("---")

    with st.sidebar:
        st.write(f"å½“å‰ç”¨æˆ·ï¼š{st.session_state.username}")
        if st.button("æ³¨é”€"):
            st.session_state.authenticated = False
            st.rerun()

        st.header("æ§åˆ¶é¢æ¿")
        detection_mode = st.radio(
            "æ£€æµ‹æ¨¡å¼",
            ["å›¾ç‰‡æ£€æµ‹", "è§†é¢‘æ£€æµ‹", "å®æ—¶æ£€æµ‹"],
            index=0
        )
        st.markdown("---")
        st.subheader("æ£€æµ‹å†å²")
        for idx, item in enumerate(st.session_state.history[-MAX_HISTORY:]):
            status_color = "#dc3545" if item["has_Fire"] else "#28a745"
            st.markdown(f"""
                <div class="video-container">
                    <div class="status-badge" style="background: {status_color}; color: white;">
                        {item['result']}
                    </div>
                    <div class="stats">
                        æ—¶é—´: {item['time']}<br>
                        å¤„ç†: {item['process_time']:.2f}s<br>
                        å¸§æ•°: {item.get('frames', 1)}
                    </div>
                </div>
            """, unsafe_allow_html=True)
        if st.button("æ¸…ç©ºå†å²"):
            st.session_state.history = []

    if detection_mode == "å›¾ç‰‡æ£€æµ‹":
        handle_image_detection(model)
    elif detection_mode == "è§†é¢‘æ£€æµ‹":
        handle_video_detection(model)
    elif detection_mode == "å®æ—¶æ£€æµ‹":
        handle_realtime_detection(model)


def main():
    if not hasattr(st.session_state, 'authenticated') or not st.session_state.authenticated:
        auth_component()
    else:
        main_app()

if __name__ == "__main__":
    main()